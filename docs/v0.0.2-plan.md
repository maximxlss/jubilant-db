# v0.0.2 ExecPlan: barebones networked transactions

This ExecPlan is a living document and must be maintained in accordance with `PLANS.md` at `/workspace/jubilant-db/PLANS.md`.

## Purpose / Big Picture

v0.0.2 demonstrates that Jubilant DB’s architecture can support remote transactions rather than only local CLI calls. A minimal server will accept simple transaction requests over the network, execute them through the existing worker and BTree plumbing, and return structured responses. A lightweight client (Python if feasible) will issue those requests, and `jubectl` will interoperate with the same flow to keep operational tooling aligned. The goal is to prove the end-to-end shape without overdesigning the protocol.

## Progress

- [x] (2025-12-17 11:59Z) Drafted the v0.0.2 ExecPlan capturing scope and acceptance.
- [x] (2025-12-17 12:35Z) Defined and documented the minimal transaction wire format and compatibility constraints in `docs/txn-wire-v0.0.2.md` (schemas, framing, and worked examples).
- [ ] Prototype Python client against a loopback stub server to validate framing and payloads.
- [x] (2025-12-17 12:52Z) Implemented the C++ server network adapter that decodes TCP JSON frames into `TransactionRequest` objects, dispatches them through `Server::SubmitTransaction`, and writes back `TransactionResult` frames.
- [ ] Add `jubectl` path (new subcommand or refactor) that speaks the same protocol for parity checks.
- [ ] Write integration tests demonstrating set/get/delete round-trips through the network stack.

## Surprises & Discoveries

- Observation: The server needed a condition variable to avoid busy-polling for completed transactions when streaming responses to clients.
  Evidence: Added `Server::WaitForResults` and used it from the network dispatch loop to sleep until results arrive.
- Observation: A frame size cap was necessary to keep malformed prefixes from allocating excessive buffers.
  Evidence: Network adapter enforces a 1 MiB maximum and closes connections that exceed it, with the limit documented in `docs/txn-wire-v0.0.2.md`.

## Decision Log

- Decision: Start with a length-prefixed JSON payload over TCP for transaction requests/responses to minimize dependencies while keeping room to swap to FlatBuffers later.
  Rationale: JSON keeps the prototype simple and debuggable, allows Python and C++ implementations without extra generators, and mirrors the in-memory `TransactionRequest` fields closely enough for this milestone.
  Date/Author: 2025-12-17 / GPT-5.1-Codex-Max.
- Decision: Use `nlohmann::json` for request/response translation and cap frames at 1 MiB to bound resource use while honoring the documented schema.
  Rationale: The header-only JSON dependency keeps parsing/serialization straightforward for both server and tests, and the cap guards against malicious prefixes during the prototype phase.
  Date/Author: 2025-12-17 / GPT-5.1-Codex-Max.

## Outcomes & Retrospective

To be filled once v0.0.2 work completes; summarize the demonstrated architecture leap and remaining gaps.

## Context and Orientation

The current CLI (`tools/jubectl/main.cpp`) operates directly on `storage::SimpleStore`, which wraps the in-process BTree and persistence stack. Server-side scaffolding already exists in `src/server/` with `TransactionReceiver`, `Worker`, and `Server` orchestrating keyed operations over `storage::btree::BTree`. Transaction shapes live in `src/txn/transaction_request.h` and transaction contexts in `src/txn/transaction_context.h`. There is no network listener or wire protocol yet, and no shared client library for `jubectl` or external clients. The target is to add a minimal network layer that converts framed requests into `TransactionRequest` objects, pushes them through `Server::SubmitTransaction`, and serializes `TransactionResult` objects back to clients. The Python client should live under `tools/clients/python/` (new), while any `jubectl` adjustments stay in `tools/jubectl/`.

## Plan of Work

Begin by locking down a minimal, documented wire contract using length-prefixed JSON frames. Each request contains a transaction id, operations array, and optional value fields; each response echoes the id, final state, and per-operation results. Add documentation for this contract in `docs/` alongside this plan. Prototype the protocol in Python to validate framing, encoding of bytes/string/int values, and error handling before touching the C++ server.

Extend the C++ server by adding a network adapter (e.g., `src/server/network_server.{h,cpp}`) that owns a blocking TCP listener and connection handler threads. Each connection reads size-prefixed JSON frames, validates them into `txn::TransactionRequest`, and forwards them to `Server::SubmitTransaction`. Responses collect from `Server::DrainCompleted()` and write back the serialized `TransactionResult` with success flags and values. Keep the adapter small and defer advanced features (TLS, multiplexing) to later versions.

Wire configuration through the existing `ConfigLoader` (if available) or a minimal config struct to set listen host/port and worker counts. Provide a server entry point binary (e.g., `src/server/main.cpp`) that instantiates the storage engine and network adapter, mirroring `jubectl`’s initialization of `SimpleStore`.

Implement a Python client library and CLI script under `tools/clients/python/` that constructs the JSON envelopes, connects via TCP, and prints responses. Keep dependencies standard-library only. Provide helper methods for `set`, `get`, `del`, and a generic transaction call that accepts multiple operations. This workstream only depends on the envelope definition and can progress in parallel with server work.

Refactor `jubectl` to optionally use the network path. If parity requires, add a `--remote <host:port>` flag or a new subcommand (`txn`) that packages the same JSON requests. Preserve existing on-disk behavior by default to avoid breaking current users while enabling side-by-side validation. `jubectl` changes depend on the envelope definition and the Python client’s schema agreement, but not on server readiness.

Add integration tests under `tests/` that start the C++ server (likely via a spawned process or in-process bootstrap), run a short Python client script to issue `set/get/del`, and assert correct responses. Include tests for invalid frames and concurrent transactions where possible. Document the full workflow in `docs/` to keep newcomers aligned. Workstreams can advance in parallel where dependencies allow: protocol documentation and Python client prototyping can proceed alongside server adapter development; `jubectl` wiring can start once the request/response envelope is frozen; integration test scaffolding can begin in tandem with server bootstrap and be finalized once handlers stabilize. Explicit constraints: (a) Envelope must be frozen before client/Jubectl milestones merge; (b) Server adapter must exist before end-to-end tests assert results; (c) Bootstrap wiring can start as soon as adapter interfaces are stubbed.

## Concrete Steps

1. Document the wire contract in `docs/` (e.g., `docs/txn-wire-v0.0.2.md`), including request/response JSON schemas, framing rules (uint32 length prefix, network byte order), and examples for `set/get/del`. **Status:** complete — see `docs/txn-wire-v0.0.2.md`. **Blocks:** none; **Unblocks:** steps 2, 3, 6.
2. Create a Python client module `tools/clients/python/jubilant_client.py` with functions `connect`, `send_transaction`, and helpers for `set/get/del`. Add a simple CLI `tools/clients/python/jubectl_client.py` to exercise these calls. This can run in parallel with step 4 as long as both honor the same envelope. **Blocks:** depends on step 1; **Unblocks:** step 8 (client half).
3. Prototype against a temporary echo server (could be a Python stub) to confirm framing; then retire stub once C++ server adapter is ready. This can proceed concurrently with documentation authoring. **Blocks:** depends on step 1; **Unblocks:** early validation for steps 2 and 4.
4. Implement `src/server/network_server.{h,cpp}` for TCP accept and per-connection loops, converting frames into `txn::TransactionRequest` and emitting `TransactionResult` frames. Integrate with `src/server/server.{h,cpp}` through `SubmitTransaction` and `DrainCompleted`. Coordinate with step 2 to keep request/response JSON aligned. **Blocks:** depends on step 1; **Unblocks:** steps 5 and 8 (server half).
5. Add a bootstrap target `src/server/main.cpp` (or extend an existing one) that loads configuration, initializes storage (via `storage::SimpleStore` or the underlying BTree), starts the worker pool, and hands sockets to the network adapter. This can start while step 4 is underway because the bootstrap wires to the adapter interface. **Blocks:** depends on adapter interface definition from step 4 (stub acceptable); **Unblocks:** step 8 environment setup.
6. Update `tools/jubectl/main.cpp` to detect `--remote` or a new `txn` command. When remote is selected, reuse the JSON envelope helpers (consider a small shared C++ helper under `tools/jubectl/` or `src/client/`). Kick off once the envelope is frozen (steps 1–2) even if the server is still stabilizing. **Blocks:** depends on step 1 (and ideally step 2 for shared helpers); **Unblocks:** step 8 (jubectl half).
7. Add CMake targets for the network server binary and ensure presets build the Python client scripts as auxiliary artifacts if needed. This can happen alongside steps 4–6. **Blocks:** depends on knowing paths from steps 2, 4, 6; **Unblocks:** CI-ready builds for step 8.
8. Write integration tests (C++ or Python) that start the server on a loopback port, run a sequence of `set/get/del` transactions via the Python client and `jubectl` remote mode, and verify responses plus BTree state on disk. Begin scaffolding early (while 4–6 progress) and finish once handlers stabilize. **Blocks:** depends on steps 2, 4, 5, 6 (for full end-to-end); can scaffold earlier using stubs from 3 and 4.
9. Update documentation (`docs/README.md` and this plan) with any discoveries, plus a short quickstart for running the server and client together. Keep this in lockstep with all streams to capture drift. **Blocks:** depends on outcomes of steps 2, 4, 6, 8; can be iteratively updated as each step lands.

## Validation and Acceptance

Acceptance hinges on an end-to-end demo: from the repository root, configuring with `cmake --preset dev-debug`, building, and launching the server with a sample config must allow a Python client to perform `set/get/del` and receive matching responses. A `jubectl --remote` invocation should produce the same results against the same server. Integration tests should pass and fail before the network path is added. Manual validation should show logs or stdout proving transaction ids and operation results echo back as expected. Error handling should return meaningful error responses for malformed JSON or missing keys.

## Idempotence and Recovery

Running the server/client repeatedly should be safe when pointing at a throwaway data directory; initialization steps should create directories if absent. The length-prefixed framing allows reconnecting cleanly after a disconnect. If integration tests leave stray processes, provide cleanup instructions (kill server by pid or ensure shutdown hooks join threads). Configurable ports avoid conflicts when rerunning.

## Artifacts and Notes

Capture sample request/response pairs in the wire contract doc, and record any divergence between Python and C++ parsing. Keep command transcripts (server start, client calls) brief and updated as behaviors change. Update this section as new evidence emerges during implementation.

## Interfaces and Dependencies

Define request JSON with fields: `txn_id` (uint64), `operations` array where each entry has `type` (`get`|`set`|`del`), `key` (string), and optional `value` holding `{kind: "bytes"|"string"|"int", data: base64|string|int64}`. Responses include `txn_id`, `state` (`committed`|`aborted`), and `operations` results mirroring the request order with `success` flag and optional `value`. The C++ network adapter should expose `Start()`/`Stop()` to manage listener lifecycle and use existing `Server::SubmitTransaction`/`DrainCompleted`. Python client depends only on `socket`, `json`, `struct`, and `argparse`.
